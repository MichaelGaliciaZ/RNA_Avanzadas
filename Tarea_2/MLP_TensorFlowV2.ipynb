{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e215834",
   "metadata": {},
   "source": [
    "# Tarea 2: Red Neuronal Perceptrón Multicapa con TensorFlow V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc1cb0",
   "metadata": {},
   "source": [
    "## Cargamos las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5265182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967b2a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "fashion_mnist = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055152f",
   "metadata": {},
   "source": [
    "## Extraemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4403262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc1741",
   "metadata": {},
   "source": [
    "## Union de Datos\n",
    "\n",
    "El dataset Fashion_Mnist cuenta con 60,000 imagenes de entrenamiento y 10,000 imagenes de prueba; Para los fines de esta tarea, se hara una división del dataset con una relación 30-70, es decir, %30 del dataset será destinado a test y %70 a entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0e5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.concatenate((x_train,x_test))\n",
    "Y=np.concatenate((y_train,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b596941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.reshape(len(X),28*28).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f0cd93",
   "metadata": {},
   "source": [
    "## Codificación One Hot Encoding \n",
    "\n",
    "Las clases se representan con etiquetas numericas en el rango de $0,\\cdots,9$:\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Identificador \t| Clase \t|\n",
    "|---\t|---\t|\n",
    "| 0 \t| T-shirt/top \t|\n",
    "| 1 \t| Trouser \t|\n",
    "| 2 \t| Pullover \t|\n",
    "| 3 \t| Dress \t|\n",
    "| 4 \t| Coat \t|\n",
    "| 5 \t| Sandal \t|\n",
    "| 6 \t| Shirt \t|\n",
    "| 7 \t| Sneaker \t|\n",
    "| 8 \t| Bag \t|\n",
    "| 9 \t| Ankle Boot \t|\n",
    "\n",
    "</div>\n",
    "\n",
    "Debido al identificador puede (o no) realizarse una codificación del tipo One Hot. Esta codificación permite que el modelo neuronal interprete la distancia entre identificadores de la misma forma, es decir, en un mal aprendizaje puede asociar la clase \"Trouser\" con la clase \"Pullover\" por que los identificadores son cercanos entre si, de forma comtraria es posible que interprete una relación (erronea) entre los identificadores mas separadas, lo cual no es relevante.\n",
    "\n",
    "A fin de observar el efecto de la codificación se realizaran dos modelos: uno con codificación ONE HOT y otro sin ella.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df244be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_HOT_ENC = OneHotEncoder(sparse=False)\n",
    "Y_OHE = Y.reshape(len(Y), 1)\n",
    "Y_OHE = ONE_HOT_ENC.fit_transform(Y_OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ef40689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones del vector de etiquetas son (70000, 10)\n",
      "Los primeros 10 elementos son \n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Las dimensiones del vector de etiquetas son {}\".format(Y.shape))\n",
    "print(\"Los primeros 10 elementos son: \\n {}\".format(Y[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b556b83e",
   "metadata": {},
   "source": [
    "## Arquitectura de el modelo\n",
    "\n",
    "Se aprovecha el paradigma de la programación orientada a objetos de Python para desarrollar una instancia que permita la declaración de la arquitectura del modelo MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc969293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_Model():\n",
    "    def __init__(self,lenght_input):\n",
    "        self.Layer_1_Weights=tf.Variable(np.random.rand(lenght_input,800))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('CIC_GPU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4dee9c77bc81e8bc3192f031245e7af43a1d4d0287b5c55b4b36e62661d36f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
